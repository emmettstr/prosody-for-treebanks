{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tgt\n",
    "import os\n",
    "import nltk\n",
    "import cmudict\n",
    "import conll\n",
    "import re\n",
    "\n",
    "def dico2FeatureString(dico):\n",
    "    \"\"\"Transforms a dictionary of Conll features into a string\"\"\"\n",
    "    feature = [\"=\".join([key, dico[key]]) for key in dico]\n",
    "    feature = \"|\".join(feature)\n",
    "    return feature\n",
    "\n",
    "def build_feature_dico(misc_features_string):\n",
    "    \"\"\"Turns a string of CONLL features into a callable dictionary\"\"\"\n",
    "    feature_dico = {}\n",
    "    for feature in misc_features_string.split(\"|\"):\n",
    "        key, value = feature.split(\"=\")\n",
    "        feature_dico[key] = value\n",
    "    return feature_dico\n",
    "\n",
    "def confirm_alignment(ref_interval, target_interval):\n",
    "    \"\"\"Takes two pitchtier intervals as entry and returns whether or not there is a temporal overlap, as well as the nature of that overlap.\"\"\"\n",
    "    \n",
    "    left_overlap = False\n",
    "    right_overlap = False\n",
    "\n",
    "    \n",
    "    #print(ref_interval, target_interval)\n",
    "    if ref_interval.text == \"\":\n",
    "        # print(\"empty string\") # debug\n",
    "        return False, left_overlap, right_overlap  # disregard pauses\n",
    "\n",
    "    if round(target_interval.end_time - ref_interval.start_time,3) <= 0.001:\n",
    "        #print(\"A\") # debug\n",
    "        return False, left_overlap, right_overlap  \n",
    "    \n",
    "    elif round(target_interval.start_time - ref_interval.end_time,3) >= -0.001:\n",
    "        #print(\"B\") # debug \n",
    "        return False, left_overlap, right_overlap  \n",
    "    \n",
    "    if  round(ref_interval.start_time - target_interval.start_time, 3) >= 0.01:\n",
    "        #print(\"C\", str(ref_interval.start_time - target_interval.start_time)) # debug\n",
    "        left_overlap = True\n",
    "    if round(target_interval.end_time - ref_interval.end_time, 3)  >= 0.01:\n",
    "        #print(\"D\") # debug\n",
    "        right_overlap = True\n",
    "\n",
    "    return True, left_overlap, right_overlap \n",
    "\n",
    "\n",
    "\n",
    "def vowel_final(word_string, dico):\n",
    "    \"\"\"Takes as entry an orthographic word string and a pronunciation dictionary, and confirms whether or not the canonical pronunciation of a that word ends in a vowel\"\"\"\n",
    "    vowels=\"aeiouAEIOU\" \n",
    "    if word_string == \"\":\n",
    "        return False\n",
    "    try:\n",
    "        phonemes = pronunciation[word_string.lower()][0]\n",
    "        if phonemes[-1][0] in vowels:\n",
    "            return True\n",
    "    except:\n",
    "        if word_string[-1] in vowels:\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "def extractProsodicAnnotation(textgrid, label_tier, label_tier2, token_tier, word_text_tier, syllable_transcription_tier):\n",
    "    \"\"\"\n",
    "    Extracts prosodic information from a .TextGrid file containing SLAM annoations and returns a dictionary of annotations.\n",
    "\n",
    "    Takes as entry:\n",
    "    * A textgrid file containing tiers corresponding to the following elements.\n",
    "    * Name of the tier containing phonetic transcriptions of syllables (syllable_transcription_tier)\n",
    "    * Names of two tiers containing global (label_tier) and local (label_tier2) SLAM annotations of syllables \n",
    "    * Name of the tier containing a token-level alignment and numeric ID in format 2:13 (utterance two, token 13) (token_tier)\n",
    "    * Name of tier containing orthographic transcription of token (word_text_tier)\n",
    "    \"\"\"\n",
    "\n",
    "    pronunciation = cmudict.dict()\n",
    "    dico = {}\n",
    "    \n",
    "    try: textgrid_object = tgt.read_textgrid(textgrid, include_empty_intervals=True, encoding=\"utf-8\")\n",
    "    except: textgrid_object = tgt.read_textgrid(textgrid, include_empty_intervals=True, encoding=\"utf-16\")\n",
    "    label_obj = textgrid_object.get_tier_by_name(label_tier)\n",
    "    label_obj2 = textgrid_object.get_tier_by_name(label_tier2)\n",
    "    token_object = textgrid_object.get_tier_by_name(token_tier)  \n",
    "    word_text_object = textgrid_object.get_tier_by_name(word_text_tier)\n",
    "    syllable_transcription_object = textgrid_object.get_tier_by_name(syllable_transcription_tier)\n",
    "    \n",
    "    i=0\n",
    "        \n",
    "    for index, token in enumerate(token_object): \n",
    "        \n",
    "        skip_features = False\n",
    "        \n",
    "        alignment_found = False\n",
    "        #alignment = False\n",
    "        syl_number = 1\n",
    "        \n",
    "        if not token.text: continue\n",
    "        \n",
    "        dico[token.text] = {}\n",
    "        dico[token.text][\"AlignBegin\"] = str(int(token.start_time*1000))\n",
    "        dico[token.text][\"AlignEnd\"] = str(int(token.end_time*1000))\n",
    "        \n",
    "        ### Debugging/holdover from earlier version ###\n",
    "        #dico[token.text][\"LeftOverlap\"] = \"False\"\n",
    "        #dico[token.text][\"RightOverlap\"] = \"False\"\n",
    "        \n",
    "        alignment, left_overlap, right_overlap = confirm_alignment(token, label_obj[i])\n",
    "        #print(alignment, left_overlap, right_overlap) # debug\n",
    "        #print(token) # debug \n",
    "        while not alignment:\n",
    "            i+=1 \n",
    "            #print(i) # debug \n",
    "            alignment, left_overlap, right_overlap = confirm_alignment(token, label_obj[i])\n",
    "            #print(alignment, left_overlap, right_overlap) # debug\n",
    "\n",
    "        \n",
    "        while alignment:\n",
    "            skip_features = False\n",
    "            if left_overlap:\n",
    "                 ### Debug ###\n",
    "                #print(dico[token.text])\n",
    "                #print(dico[token_object[index-1].text])\n",
    "                #print(token.text, token_object[index-1].text)\n",
    "                #print(token, label_obj[i])\n",
    "                #print(token_object[index-1].text)\n",
    "                #print(left_overlap)\n",
    "\n",
    "                try: \n",
    "                    if vowel_final(word_text_object[index-1].text, pronunciation): \n",
    "                        dico[token.text][\"Syl\"+str(syl_number)] = \"FUSED\"\n",
    "                        skip_features = True\n",
    "\n",
    "                    ### Handles rare cases of triple fusions betweeen syllables\n",
    "\n",
    "                    elif dico[token_object[index-1].text][\"Syl1\"] == \"FUSED\" and \"Syl2\" not in dico[token_object[index-1].text]:\n",
    "                        dico[token.text][\"Syl\"+str(syl_number)] = \"FUSED\"\n",
    "                        skip_features = True\n",
    "\n",
    "                    elif \"Syl1AlignBegin\" in dico[token_object[index-1].text] and str(dico[token_object[index-1].text]['Syl1AlignBegin']) == str(int(label_obj[i].start_time*1000)):\n",
    "                        dico[token.text][\"Syl\"+str(syl_number)] = \"FUSED\"\n",
    "                        skip_features = True\n",
    "\n",
    "                    else:\n",
    "                        dico[token.text][\"Syl\"+str(syl_number)+\"ExternalOnset\"] = \"True\"\n",
    "                except:\n",
    "                    print(\"problem on {}, confirm output\".format(label_obj[i]))\n",
    "\n",
    "                #dico[token.text][\"LeftOverlap\"] = \"True\"\n",
    "                \n",
    "            if right_overlap:\n",
    "                if vowel_final(word_text_object[index].text, pronunciation) != True and label_obj[i].start_time > token.start_time:  \n",
    "                    skip_features = True\n",
    "\n",
    "                #dico[token.text][\"RightOverlap\"] = \"True\"\n",
    "                \n",
    "            if skip_features == False:\n",
    "            \n",
    "                if label_obj[i].text:\n",
    "                    dico[token.text][\"Syl\"+str(syl_number)+\"Glo\"] = label_obj[i].text\n",
    "                    dico[token.text][\"Syl\"+str(syl_number)+\"Loc\"] = label_obj2[i].text\n",
    "                    dico[token.text][\"Syl\"+str(syl_number)+\"Duration\"] = str(int((label_obj[i].end_time - label_obj[i].start_time)*1000))\n",
    "                    \n",
    "                    feature_dico = contourToFeatures(label_obj[i].text, \"Glo\")\n",
    "                    feature_dico.update(contourToFeatures(label_obj2[i].text, \"Loc\"))\n",
    "\n",
    "                    for feature in feature_dico.keys():\n",
    "                        dico[token.text][\"Syl\"+str(syl_number)+feature] = feature_dico[feature]\n",
    "                    dico[token.text][\"SyllableCount\"] = str(syl_number)\n",
    "\n",
    "                    #dico[token.text][\"SylStart\"] = label_obj[i].start_time\n",
    "\n",
    "                else: \n",
    "                    dico[token.text][\"Syl\"+str(syl_number)+\"Glo\"] = \"X\"\n",
    "                    dico[token.text][\"Syl\"+str(syl_number)+\"Loc\"] = \"X\"\n",
    "                    #dico[token.text][\"SylStart\"] = label_obj[i].start_time\n",
    "                    \n",
    "                \n",
    "                dico[token.text][\"Syl\"+str(syl_number)+\"AlignBegin\"] = str(int(label_obj[i].start_time*1000))\n",
    "                dico[token.text][\"Syl\"+str(syl_number)+\"AlignEnd\"] = str(int(label_obj[i].end_time*1000))\n",
    "\n",
    "                dico[token.text][\"Syl\"+str(syl_number)] = syllable_transcription_object[i].text\n",
    "\n",
    "\n",
    "            syl_number+=1\n",
    "            i+=1\n",
    "            if i == len(label_obj):\n",
    "                break\n",
    "                \n",
    "            alignment, left_overlap, right_overlap = confirm_alignment(token, label_obj[i])\n",
    "            #print(alignment, left_overlap, right_overlap)\n",
    "\n",
    "        \n",
    "        i-=1\n",
    "        \n",
    "\n",
    "                \n",
    "    return dico\n",
    "\n",
    "def translate_code(code):\n",
    "    \"\"\"Takes in entry a textual SLAM label and converts it into a list of numeric values to facilitate extraction of features\"\"\"\n",
    "\n",
    "    translated_code = []\n",
    "    for letter in code[0:2]:\n",
    "        if letter == \"L\":\n",
    "            translated_code.append(1)\n",
    "        elif letter == \"l\":\n",
    "            translated_code.append(2)\n",
    "        elif letter == \"m\":\n",
    "            translated_code.append(3)\n",
    "        elif letter == \"h\":\n",
    "            translated_code.append(4)\n",
    "        elif letter == \"H\":\n",
    "            translated_code.append(5)\n",
    "\n",
    "    if len(code) > 2:\n",
    "        if code[2] == \"L\":\n",
    "            translated_code.append((1, int(code[3])))\n",
    "        elif code[2] == \"l\":\n",
    "            translated_code.append((2, int(code[3])))\n",
    "        elif code[2] == \"m\":\n",
    "            translated_code.append((3, int(code[3])))\n",
    "        elif code[2] == \"h\":\n",
    "            translated_code.append((4, int(code[3])))\n",
    "        elif code[2] == \"H\":\n",
    "            translated_code.append((5, int(code[3])))\n",
    "\n",
    "    return translated_code\n",
    "            \n",
    "def contourToFeatures(contour_label, suffix=\"\"):\n",
    "    \"\"\"Takes as entry a textual SLAM label and returns a set of categorical prosodic features describing the label.\"\"\"\n",
    "    \n",
    "    dico = {}\n",
    "\n",
    "    code = translate_code(contour_label)\n",
    "\n",
    "    if code[0] == code[1]:\n",
    "        dico[\"Slope\"+suffix] = \"Flat\"\n",
    "    elif code[0] < code[1]:\n",
    "        dico[\"Slope\"+suffix] = \"Rise\"\n",
    "    elif code[0] > code[1]:\n",
    "        dico[\"Slope\"+suffix] = \"Fall\"\n",
    "\n",
    "    if len(code) == 2:\n",
    "        height = (code[0] + code[1]) / 2\n",
    "    if len(code) == 3:\n",
    "        height = (code[0] + code[1] + code[2][0]) / 3\n",
    "\n",
    "    if height >= 3.5:\n",
    "        dico[\"AvgHeight\"+suffix] = \"H\"\n",
    "    elif height < 2.5:\n",
    "        dico[\"AvgHeight\"+suffix] = \"L\"\n",
    "    else: \n",
    "        dico[\"AvgHeight\"+suffix] = \"M\"\n",
    "\n",
    "    amplitude = abs(code[0] - code[1])\n",
    "    if amplitude <= 1:\n",
    "        dico[\"PitchRange\"+suffix] = \"L\"\n",
    "    elif amplitude >= 3:\n",
    "        dico[\"PitchRange\"+suffix] = \"H\"\n",
    "    else: \n",
    "        dico[\"PitchRange\"+suffix] = \"M\"\n",
    "        \n",
    "    return dico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciation = cmudict.dict() # Pronunciation dictionary: to modify according to the language chosen\n",
    "syl_tier = \"SyllablesStyleGlo\" # Tier containing global contour\n",
    "syl_tier2 = \"SyllablesStyleLoc\" # Tier containing local contour\n",
    "word_tier = \"Word-ID\" # Tier containing numeric ID for token \n",
    "word_text_tier = \"Word-Text\" # Tier containing text token text \n",
    "syllable_text_tier = \"Syllables\" # Tier containing syllabic transcriptions \n",
    "slam_files = glob.glob(\"SLAM_output/*.TextGrid\") # Folder containing SLAM labels in TextGrid format\n",
    "conll_infiles = glob.glob(\"CONLL_files/*.conllu\") # Folder containing CONLLU files to which prosodic information will be added\n",
    "conll_outfolder = \"CONLL_outfiles/\"\n",
    "\n",
    "# If running this script a second time, useful for renaming features \n",
    "feature_rename_dict = {\"OldFeatname\" : \"NewFeatname\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill CONLLU files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slam_file in sorted(slam_files):\n",
    "    basename = os.path.basename(slam_file)[:-9]\n",
    "    print(\"treating\", basename)\n",
    "    annotations = extractProsodicAnnotation(slam_file, syl_tier, syl_tier2, word_tier, word_text_tier, syllable_text_tier)\n",
    "    for infile in conll_infiles:\n",
    "        \n",
    "        if os.path.basename(infile)[:len(basename)] == basename:\n",
    "            trees=conll.conllFile2trees(infile)\n",
    "            for treei, tree in enumerate(trees):\n",
    "                for token in tree:\n",
    "                    identifier = str(treei+1)+\":\"+str(token)\n",
    "                    misc_features = tree[token]['misc']\n",
    "                    feature_dico = build_feature_dico(misc_features)\n",
    "                    \n",
    "                    \n",
    "                    features_to_delete = []\n",
    "                    \n",
    "                    new_feature_dico = {}\n",
    "                    for feature in feature_dico.keys():\n",
    "                        #print(feature)\n",
    "                        if re.match(\"Syl[0-9].*\", feature):\n",
    "                            if \"Amplitude\" not in feature:\n",
    "                                features_to_delete.append(feature)\n",
    "                            #print(features_to_delete)\n",
    "                            \n",
    "                        #print(feature)\n",
    "                        if feature[4:] in feature_rename_dict.keys():\n",
    "                            newfeat = feature.replace(feature[4:], feature_rename_dict[feature[4:]])\n",
    "                            #print(feature, newfeat)\n",
    "                            newval = feature_dico[feature]\n",
    "                            new_feature_dico[newfeat] = newval\n",
    "                            features_to_delete.append(feature)\n",
    "                            #print(feature_dico)\n",
    "\n",
    "                        \"\"\"\"   \n",
    "                        if feature == \"F0Enonce\":\n",
    "                            newfeat = feature.replace(feature, feature_rename_dict[feature])\n",
    "                            #print(feature, newfeat)\n",
    "                            newval = feature_dico[feature]\n",
    "                            new_feature_dico[newfeat] = newval\n",
    "                            features_to_delete.append(feature)\n",
    "                            #print(feature_dico)\n",
    "                        \"\"\"\n",
    "                            \n",
    "                    for feature in new_feature_dico.keys():\n",
    "                        feature_dico[feature] = new_feature_dico[feature]\n",
    "                        \n",
    "                    \n",
    "                    for feature in features_to_delete:\n",
    "                        if feature in feature_dico.keys():\n",
    "                            del feature_dico[feature]\n",
    "                    #print(feature_dico)\n",
    "                    \n",
    "                        \n",
    "                    #print(feature_dico)\n",
    "                    if identifier in annotations.keys():\n",
    "                        for item in annotations[identifier]:\n",
    "                            #print(identifier, item)\n",
    "                            feature_dico[item] = annotations[identifier][item]\n",
    "                        \n",
    "                        if \"Syl1\" in feature_dico.keys() and feature_dico[\"Syl1\"] == \"FUSED\":\n",
    "                            #print(\"hi\")\n",
    "                            if \"Syl1Duration\" in feature_dico.keys():\n",
    "                                del feature_dico[\"Syl1Duration\"]\n",
    "                            if \"Syl1MeanF0\" in feature_dico.keys():\n",
    "                                del feature_dico[\"Syl1MeanF0\"]\n",
    "                            if \"Syl1SemitonesFromUtteranceMean\" in feature_dico.keys():\n",
    "                                del feature_dico[\"Syl1SemitonesFromUtteranceMean\"]\n",
    "                        #print(identifier)\n",
    "                        #print(feature_string)\n",
    "                        feature_string = dico2FeatureString(feature_dico)\n",
    "                        tree[token]['misc'] = feature_string\n",
    "                    \n",
    "                    \"\"\"\n",
    "                    identifier = str(treei+1)+\":\"+str(token)\n",
    "                    misc_features = tree[token]['misc']\n",
    "                    \n",
    "                    if identifier in annotations.keys():              \n",
    "                        for item in annotations[identifier]:\n",
    "                            misc_features = misc_features + \"|\"\n",
    "                            featstring = item+\"=\"+annotations[identifier][item]\n",
    "                            misc_features = misc_features + featstring\n",
    "                    tree[token]['misc'] = misc_features\n",
    "                    #print(tree[token]['misc'])\n",
    "                    \"\"\"\n",
    "                    \n",
    "            conll.trees2conllFile(trees, conll_outfolder+os.path.basename(infile))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
